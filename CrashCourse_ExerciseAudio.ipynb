{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Learning to recognise touch sounds\n",
    "This exercise will look at recognising the audio registered by a piezo contact microphone on a mobile device when different parts of it are touched by a user. This is data from the **Stane** project ([Paper](http://www.dcs.gla.ac.uk/~rod/publications/MurWilHugQua08.pdf) and [video](http://www.dcs.gla.ac.uk/~rod/Videos/i_chi2.mov)), which used 3D printed surfaces to make super-cheap touch controllers.\n",
    "\n",
    "<img src=\"imgs/stane_1.png\" width=\"400px\">\n",
    "<img src=\"imgs/stane_2.png\" width=\"400px\">\n",
    "\n",
    "The machine learning problem is simple: given a set of recordings of a user rubbing discrete touch zones on this 3D printed case, train a classifier which can distinguish which zone is being touched. This is in essence similar to speech recognition, but with a much simpler acoustic problem and no need to deal with language modeling.\n",
    "\n",
    "We will use multi-class classification to distinguish the touch zones from the audio alone. We can assume a small number of discrete touch areas, and that there is no model governing how they might be touched (i.e. touches happen at random).\n",
    "\n",
    "\n",
    "\n",
    "## A data processing pipeline\n",
    "We need to develop a *pipeline* to process the data. There are several stages common to most supervised learning tasks:\n",
    "\n",
    "1. Loading the original data (from files, databases etc.)\n",
    "1. Pre-processing (removing outliers, resampling or interpolating, raw normalisation)\n",
    "1. Feature extraction (transforming data into fixed length feature vectors)\n",
    "1. Feature processing (offset removal and normalisation)\n",
    "1. Data splitting (dividing into testing and training sections)\n",
    "1. Classification (training the classifier)\n",
    "1. Evaluation (testing the classifier performance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standard imports\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "import scipy.signal as sig\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data\n",
    "The first thing we need to do is to load the data. The data is in `datasets/stane/` and consists of four wave files from scratching four different surfaces, each 30 seconds in length, 44Khz, 16 bit PCM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Error 2] The system cannot find the file specified: u'datasets'\n",
      "c:\\work\\summerschool2015\n",
      " Volume in drive C is OS\n",
      " Volume Serial Number is F2AC-1EA1\n",
      "\n",
      " Directory of c:\\work\\summerschool2015\n",
      "\n",
      "10/06/2015  17:17    <DIR>          .\n",
      "10/06/2015  17:17    <DIR>          ..\n",
      "10/06/2015  08:56               759 .gitignore\n",
      "10/06/2015  11:15    <DIR>          .ipynb_checkpoints\n",
      "10/06/2015  17:17             1,344 CrashCourse_ExerciseAudio.ipynb\n",
      "10/06/2015  15:57           298,980 CrashCourse_IntroIpython.ipynb\n",
      "10/06/2015  16:27             4,291 CrashCourse_Lecture1.ipynb\n",
      "10/06/2015  15:31             3,058 CrashCourse_Lecture2.ipynb\n",
      "10/06/2015  10:47               577 CrashCourse_Lecture3.ipynb\n",
      "10/06/2015  16:25             1,055 CrashCourse_Lecture4.ipynb\n",
      "10/06/2015  11:14            10,127 CrashCourse_Resources.ipynb\n",
      "10/06/2015  09:52    <DIR>          imgs\n",
      "10/06/2015  08:56             1,096 LICENSE\n",
      "10/06/2015  08:56                83 README.md\n",
      "10/06/2015  15:57             4,081 SummerSchoolIntro.ipynb\n",
      "10/06/2015  10:59                78 Untitled.ipynb\n",
      "              12 File(s)        325,529 bytes\n",
      "               4 Dir(s)  399,014,903,808 bytes free\n"
     ]
    }
   ],
   "source": [
    "%cd datasets\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load each of the files into sound_files\n",
    "sound_files = []\n",
    "for texture in \"1234\":\n",
    "    # load the wavefile\n",
    "    sr, data = wavfile.load(\"scratch_%d\"%texture)\n",
    "    sound_files.append(data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Step 2: Pre-processing\n",
    "## Step 3: Feature extraction\n",
    "## Step 4: Building a classifier\n",
    "## Step 6: Evaluating performance\n",
    "## Step 7: A better classifier\n",
    "## Step 8: Better evaluation methods\n",
    "## Step 9: Experiment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
